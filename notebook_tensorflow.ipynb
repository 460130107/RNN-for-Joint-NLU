{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://www.isca-speech.org/archive/Interspeech_2016/pdfs/1352.PDF\n",
    "* https://arxiv.org/pdf/1409.0473.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, w2ix):\n",
    "    idxs = list(map(lambda w: w2ix[w] if w in w2ix.keys() else w2ix[\"<UNK>\"], seq))\n",
    "    # todo\n",
    "    tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else Variable(torch.LongTensor(idxs))\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]  # 二维展成一维 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = open(\"dataset/atis-2.train.w-intent.iob\",\"r\").readlines()\n",
    "train = [t[:-1] for t in train]  # 去掉'\\n'\n",
    "# 数据的一行像这样：'BOS i want to fly from baltimore to dallas round trip EOS\\tO O O O O O B-fromloc.city_name O B-toloc.city_name B-round_trip I-round_trip atis_flight'\n",
    "# 分割成这样[原始句子的词，标注的序列，intent]\n",
    "train = [[t.split(\"\\t\")[0].split(\" \"),t.split(\"\\t\")[1].split(\" \")[:-1],t.split(\"\\t\")[1].split(\" \")[-1]] for t in train]\n",
    "train = [[t[0][1:-1],t[1][1:],t[2]] for t in train]  # 将BOS和EOS去掉，并去掉对应标注序列中相应的标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_in, seq_out, intent = list(zip(*train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(flatten(seq_in))\n",
    "slot_tag = set(flatten(seq_out))\n",
    "intent_tag = set(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"area tuesdays get fifth tuesday heading straight reverse 1222 booking detroit evening turboprop zone stand fit visit thereafter oakland near 823 greatest nevada define sorry all calling travel worth october eye grounds around airlines 4400 dinnertime numbers has bring francisco boston that first hi seventeenth h america help home like 106 month wants cities no 82 december columbus scheduled say serves return thing kinds rental for american's great thursday canadian ohio 2134 qualify ten 650 1500 there 1245 economy morning sa hopefully look include meals i've coach connect sure 415 friends 3 following b sort hartfield second inexpensive 343 twentieth by over limo highest run eighteenth nw my trying mia thrift operation fare lunch nineteenth reservation rent database 1055 wednesday's go represented thursdays codes 928 flights begins names it's using trips baltimore hou makes 747 dc10 intercontinental friday along about meal time should february tacoma both transport repeat across only sd let scenario charlotte 727 equal let's level dl belong depart sunday book sixteen cincinnati 459 alaska please april passengers possible 430 with downtown that's destination various sunday's being i'm find schedule connection southwest ap57 1145 classes 3724 departing weekdays continuing stopping ea toward york sundays nonstops staying gets less monday airports provide very 497766 orlando international pm so me 1850 trans 815 on houston don't cheap 1 sometime third still who arriving take 771 once difference far 1200 need 1100 cheapest tell between newark well 1133 goes bur 734 mondays capacity bna do 5 before either seattle taxi 9 offers spend arrange 2153 priced number business nonstop put dulles oh anywhere carried right now hours preferably got delta toronto are los price tickets 225 cp but 934 laying d last montreal 0900 traveling airplane tower concerning late sixteenth world noontime connects fly connecting largest logan ontario into question 43 630 466 1026 having departs while 212 name 311 car minneapolis 500 such meaning can leaving stapleton connections back f yn planes 718 405 qw nashville 737 arrangements what 1205 305 people midway six many jet michigan 150 s through limousine directly airfare stopovers 110 755 takes maximum 838 long 4 mealtime afternoon how same times 819 345 without may seven airline coming repeating f28 lives interested arizona miami stopover costs st. taking jose ord able 767 know fn 1230 somebody next any departure services thirtieth 825 dc 72s 323 information denver lowest again o'clock three closest at abbreviation y stops breakfast 733 mornings returning 1288 them 201 139 705 january am just 19 746 doesn't working provides thirty paul does serve direct 2 ap80 730 us round 11 choices kansas advertises more today saturdays economic eastern 1765 cars uses 1020 qx 810 route september 21 270 display cleveland 400 hello sfo guardia must 1209 3357 arrival 757 inform air amount midnight midwest within 402 1991 california 813 originate earliest 1300 555 217 requesting companies dallas where aa service seating lake petersburg beach thank milwaukee general 100 twelfth 1045 leave ticket non order 1115 505 qo their bwi some schedules fares earlier date class plan distance besides wednesdays supper m american reaches operating too city tomorrow united dfw seats layover days hp missouri ninth 645 utah nationair wish 130 ground july list yes as 229 than eighth 71 539 rates bound explain ac limousines co whether place takeoff describe tenth here lands looking during 1024 enroute most ff oak pennsylvania day originating abbreviations 279 or jersey 1039 yyz transcontinental restrictions fifteenth twenty 417 friday's express reaching dollars diego ap offer live via minimum an one colorado vegas indianapolis airplanes rentals continent northwest 420 other make capacities two phoenix 7 equipment 315 designate landing noon be lufthansa expensive 1940 carries twa 281 types starting 1600 another cost philadelphia give 1000 burbank j31 seventh flying kind county later angeles m80 early nighttime i'd 296 i'll year pearson listing under arrive code 230 wednesday delta's fort arrives travels 1993 the 352 atlanta's ewr symbols of a departures new else ua latest fourth these we're fine usa 1030 smallest 445 carolina 73s prefer chicago 1130 300 200 la november mco making type love rate 1110 includes tennessee jfk ls listed regarding it memphis single thirteenth 1158 eleven canada washington minnesota runs 10 1992 shortest to 416 boeing will san airfares 720 available stands want arrivals used okay 1291 i including texas georgia airport stop located mitchell wanted dinner north c show way 80 red out up eight buy if transportation week q come 12 after what're 852 four fourteenth instead quebec would serving your 530 afternoons atlanta flies 269 town iah 615 you 515 932 each 57 324 actually listings when 8 start salt atl 137338 lester eleventh landings 1505 night sixth what's march 297 leaves prices indiana charges flight is mean lastest everywhere york's much 2100 329 163 soon pittsburgh also served beginning plane total las in final florida see tampa 1017 august which provided could different this takeoffs field locate close continental june approximately reservations d10 options one's vicinity d9s 210 serviced currently land westchester west proper saturday use philly itinerary catch and have from seventeen snack 6 they 723 going weekday 257 those louis 845 train then offered daily local 98 aircraft trip 1700 55 restriction 1220 least\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH=50\n",
    "sin=[]\n",
    "sout=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding，原始序列和标注序列结尾+<EOS>+n×<PAD>\n",
    "for i in range(len(seq_in)):\n",
    "    temp = seq_in[i]\n",
    "    if len(temp)<LENGTH:\n",
    "        temp.append('<EOS>')\n",
    "        while len(temp)<LENGTH:\n",
    "            temp.append('<PAD>')\n",
    "    else:\n",
    "        temp = temp[:LENGTH]\n",
    "        temp[-1]='<EOS>'\n",
    "    sin.append(temp)\n",
    "    \n",
    "    temp = seq_out[i]\n",
    "    if len(temp)<LENGTH:\n",
    "        while len(temp)<LENGTH:\n",
    "            temp.append('<PAD>')\n",
    "    else:\n",
    "        temp = temp[:LENGTH]\n",
    "        temp[-1]='<EOS>'\n",
    "    sout.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成word2index\n",
    "word2index = {'<PAD>': 0, '<UNK>':1,'<SOS>':2,'<EOS>':3}\n",
    "for token in vocab:\n",
    "    if token not in word2index.keys():\n",
    "        word2index[token]=len(word2index)\n",
    "\n",
    "# 生成index2word\n",
    "index2word = {v:k for k,v in word2index.items()}\n",
    "\n",
    "# 生成tag2index\n",
    "tag2index = {'<PAD>' : 0}\n",
    "for tag in slot_tag:\n",
    "    if tag not in tag2index.keys():\n",
    "        tag2index[tag] = len(tag2index)\n",
    "        \n",
    "# 生成index2tag\n",
    "index2tag = {v:k for k,v in tag2index.items()}\n",
    "\n",
    "# 生成intent2index\n",
    "intent2index={}\n",
    "for ii in intent_tag:\n",
    "    if ii not in intent2index.keys():\n",
    "        intent2index[ii] = len(intent2index)\n",
    "\n",
    "# 生成index2intent\n",
    "index2intent = {v:k for k,v in intent2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = list(zip(sin,sout,intent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atis_flight'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size,train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex=0\n",
    "    eindex=batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex+batch_size\n",
    "        sindex = temp\n",
    "        \n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "\n",
    "for tr in train:\n",
    "    \n",
    "    temp = prepare_sequence(tr[0],word2index)\n",
    "    temp = temp.view(1,-1)\n",
    "    \n",
    "    temp2 = prepare_sequence(tr[1],tag2index)\n",
    "    temp2 = temp2.view(1,-1)\n",
    "    \n",
    "    temp3 = Variable(torch.LongTensor([intent2index[tr[2]]])).cuda() if USE_CUDA else Variable(torch.LongTensor([intent2index[tr[2]]]))\n",
    "    \n",
    "    train_data.append((temp,temp2,temp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,embedding_size, hidden_size,batch_size=16 ,n_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers, batch_first=True,bidirectional=True)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.lstm.weight.data.\n",
    "    \n",
    "    def init_hidden(self,input):\n",
    "        hidden = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
    "        context = Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
    "        return (hidden,context)\n",
    "     \n",
    "    def forward(self, input,input_masking):\n",
    "        \"\"\"\n",
    "        input : B,T (LongTensor)\n",
    "        input_masking : B,T (PAD 마스킹한 ByteTensor)\n",
    "        \n",
    "        <PAD> 제외한 리얼 Context를 다시 만들어서 아웃풋으로\n",
    "        \"\"\"\n",
    "        \n",
    "        self.hidden = self.init_hidden(input)\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        output, self.hidden = self.lstm(embedded, self.hidden)\n",
    "        \n",
    "        real_context=[]\n",
    "        \n",
    "        for i,o in enumerate(output): # B,T,D\n",
    "            real_length = input_masking[i].data.tolist().count(0) # 실제 길이\n",
    "            real_context.append(o[real_length-1])\n",
    "            \n",
    "        return output, torch.cat(real_context).view(input.size(0),-1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,slot_size,intent_size,embedding_size,hidden_size,batch_size=16,n_layers=1,dropout_p=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.slot_size = slot_size\n",
    "        self.intent_size = intent_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.embedding_size = embedding_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Define the layers\n",
    "        self.embedding = nn.Embedding(self.slot_size, self.embedding_size) #TODO encoder와 공유하도록 하고 학습되지 않게..\n",
    "\n",
    "        #self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.embedding_size+self.hidden_size*2, self.hidden_size, self.n_layers, batch_first=True)\n",
    "        self.attn = nn.Linear(self.hidden_size,self.hidden_size) # Attention\n",
    "        self.slot_out = nn.Linear(self.hidden_size*2, self.slot_size)\n",
    "        self.intent_out = nn.Linear(self.hidden_size*2,self.intent_size)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.out.bias.data.fill_(0)\n",
    "        #self.out.weight.data.uniform_(-0.1, 0.1)\n",
    "        #self.lstm.weight.data.\n",
    "    \n",
    "    def Attention(self, hidden, encoder_outputs, encoder_maskings):\n",
    "        \"\"\"\n",
    "        hidden : 1,B,D\n",
    "        encoder_outputs : B,T,D\n",
    "        encoder_maskings : B,T # ByteTensor\n",
    "        \"\"\"\n",
    "        \n",
    "        hidden = hidden.squeeze(0).unsqueeze(2)  # 히든 : (1,배치,차원) -> (배치,차원,1)\n",
    "        \n",
    "        batch_size = encoder_outputs.size(0) # B\n",
    "        max_len = encoder_outputs.size(1) # T\n",
    "        energies = self.attn(encoder_outputs.contiguous().view(batch_size*max_len,-1)) # B*T,D -> B*T,D\n",
    "        energies = energies.view(batch_size,max_len,-1) # B,T,D (배치,타임,차원)\n",
    "        attn_energies = energies.bmm(hidden).transpose(1,2) # B,T,D * B,D,1 --> B,1,T\n",
    "        attn_energies = attn_energies.squeeze(1).masked_fill(encoder_maskings,-1e12) # PAD masking\n",
    "        \n",
    "        alpha = F.softmax(attn_energies) # B,T\n",
    "        alpha = alpha.unsqueeze(1) # B,1,T\n",
    "        context = alpha.bmm(encoder_outputs) # B,1,T * B,T,D => B,1,D\n",
    "        \n",
    "        return context # B,1,D\n",
    "    \n",
    "    def init_hidden(self,input):\n",
    "        hidden = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2,input.size(0), self.hidden_size))\n",
    "        context = Variable(torch.zeros(self.n_layers*1, input.size(0), self.hidden_size)).cuda() if USE_CUDA else Variable(torch.zeros(self.n_layers*2, input.size(0), self.hidden_size))\n",
    "        return (hidden,context)\n",
    "    \n",
    "    def forward(self, input,context,encoder_outputs,encoder_maskings,training=True):\n",
    "        \"\"\"\n",
    "        input : B,L(length)\n",
    "        enc_context : B,1,D\n",
    "        \"\"\"\n",
    "        # Get the embedding of the current input word\n",
    "        embedded = self.embedding(input)\n",
    "        hidden = self.init_hidden(input)\n",
    "        decode=[]\n",
    "        aligns = encoder_outputs.transpose(0,1)\n",
    "        length = encoder_outputs.size(1)\n",
    "        for i in range(length): # Input_sequence와 Output_sequence의 길이가 같기 때문..\n",
    "            aligned = aligns[i].unsqueeze(1)# B,1,D\n",
    "            _, hidden = self.lstm(torch.cat((embedded,context,aligned),2), hidden) # input, context, aligned encoder hidden, hidden\n",
    "            \n",
    "            # for Intent Detection\n",
    "            if i==0: \n",
    "                intent_hidden = hidden[0].clone() \n",
    "                intent_context = self.Attention(intent_hidden, encoder_outputs,encoder_maskings) \n",
    "                concated = torch.cat((intent_hidden,intent_context.transpose(0,1)),2) # 1,B,D\n",
    "                intent_score = self.intent_out(concated.squeeze(0)) # B,D\n",
    "\n",
    "            concated = torch.cat((hidden[0],context.transpose(0,1)),2)\n",
    "            score = self.slot_out(concated.squeeze(0))\n",
    "            softmaxed = F.log_softmax(score)\n",
    "            decode.append(softmaxed)\n",
    "            _,input = torch.max(softmaxed,1)\n",
    "            embedded = self.embedding(input.unsqueeze(1))\n",
    "            \n",
    "            # 그 다음 Context Vector를 Attention으로 계산\n",
    "            context = self.Attention(hidden[0], encoder_outputs,encoder_maskings) \n",
    "        # 요고 주의! time-step을 column-wise concat한 후, reshape!!\n",
    "        slot_scores = torch.cat(decode,1)\n",
    "        return slot_scores.view(input.size(0)*length,-1), intent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.001\n",
    "EMBEDDING_SIZE=64\n",
    "HIDDEN_SIZE=64\n",
    "BATCH_SIZE=16\n",
    "LENGTH=50\n",
    "STEP_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(word2index),EMBEDDING_SIZE,HIDDEN_SIZE)\n",
    "decoder = Decoder(len(tag2index),len(intent2index),len(tag2index)//3,HIDDEN_SIZE*2)\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "encoder.init_weights()\n",
    "decoder.init_weights()\n",
    "\n",
    "loss_function_1 = nn.CrossEntropyLoss(ignore_index=0)\n",
    "loss_function_2 = nn.CrossEntropyLoss()\n",
    "enc_optim= optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
    "dec_optim = optim.Adam(decoder.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for step in range(STEP_SIZE):\n",
    "    losses=[]\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE,train_data)):\n",
    "        x,y_1,y_2 = zip(*batch)\n",
    "        x = torch.cat(x)\n",
    "        tag_target = torch.cat(y_1)\n",
    "        intent_target = torch.cat(y_2)\n",
    "        x_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in x]).view(BATCH_SIZE,-1)\n",
    "        y_1_mask = torch.cat([Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))).cuda() if USE_CUDA else Variable(torch.ByteTensor(tuple(map(lambda s: s ==0, t.data)))) for t in tag_target]).view(BATCH_SIZE,-1)\n",
    " \n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "\n",
    "        output, hidden_c = encoder(x,x_mask)\n",
    "        start_decode = Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).cuda().transpose(1,0) if USE_CUDA else Variable(torch.LongTensor([[word2index['<SOS>']]*BATCH_SIZE])).transpose(1,0)\n",
    "\n",
    "        tag_score, intent_score = decoder(start_decode,hidden_c,output,x_mask)\n",
    "\n",
    "        loss_1 = loss_function_1(tag_score,tag_target.view(-1))\n",
    "        loss_2 = loss_function_2(intent_score,intent_target)\n",
    "\n",
    "        loss = loss_1+loss_2\n",
    "        losses.append(loss.data.cpu().numpy()[0] if USE_CUDA else loss.data.numpy()[0])\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm(encoder.parameters(), 5.0)\n",
    "        torch.nn.utils.clip_grad_norm(decoder.parameters(), 5.0)\n",
    "\n",
    "        enc_optim.step()\n",
    "        dec_optim.step()\n",
    "\n",
    "        if i % 100==0:\n",
    "            print(\"Step\",step,\" epoch\",i,\" : \",np.mean(losses))\n",
    "            losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
